%% Ejercicios Puntuables de Localizaci√≥n
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% Control y Programaci√≥n de Robots
% 
% Ricardo Panero Lamothe
% 
% Diciembre de 2022
% 
% 
% 
% 
% 
% 
%% 
% 
% 
% 
% 
% 
% 
% 
%% Introducci√≥n
% Para el desarrollo de la tarea se ha reestructurado por completo el c√≥digo 
% de los scripts proporcionados, intentando que la mayor parte sea reutilizable 
% en las dos pr√°cticas.
% 
% En una primera iteraci√≥n, se han desarrollado funciones para programar la 
% l√≥gica de forma procedural, pero m√°s tarde se ha reescrito el c√≥digo utilizando 
% programaci√≥n orientada a objetos.
% 
% Algunas funciones son comunes al enfoque de procedural y orientaci√≥n a objetos:
%% 
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/angle_sum.m angle_sum>: 
% Sustituye a la funci√≥n AngleWrap. Suma dos √°ngulos y devuelve el resultado entre 
% -180¬∫ y 180¬∫; para ello sumamos 10 vueltas y media, obtenemos el resto de dividir 
% por 360¬∫ y restamos la media vuelta de m√°s
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/dist_angle.m dist_angle>: 
% Calcula la distancia y √°ngulo desde una pose a una baliza y la devuelve en forma 
% de vector columna.
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/comp_odom.m comp_odom>: 
% Composici√≥n odom√©trica de una pose con una actualizaci√≥n. Se define la matriz 
% de rotaci√≥n y se usa √°lgebra matricial. El √°ngulo de la pose resultante se normaliza 
% a -180-180¬∫ por medio de la funci√≥n angle_sum
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/comp_noisy.m comp_noisy>: 
% Composici√≥n de una pose o con una actualizaci√≥n, pero a√±adiendo ruido al final. 
% El ruido simula que los actuadores del robot no son completamente precisos, 
% por lo que al realizar la acci√≥n el robot no llega al punto deseado. 
%% 
% Con el enfoque procedural se definieron las siguientes funciones:
%% 
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/create_map.m create_map>: 
% Crea un mapa y genera un juego de balizas en posiciones aleatorias. Devuelve 
% una estructura que contiene el n√∫mero de balizas, el tama√±o del mapa y una matriz 
% de 2xn posiciones de balizas
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/create_robot.m create_robot>: 
% Crea un robot e inicializa sus poses real, odom√©trica y estimada; registra los 
% par√°metros de precisi√≥n de actuadores y sensores, as√≠ como el rango de los sensores; 
% inicializa los par√°metros de configuraci√≥n que requieren los algoritmos LSE 
% y FP; e inicializa las matrices para registrar errores y sensores que se utilizan 
% en cada iteraci√≥n
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/read_sensors.m read_sensors>: 
% Desde la posici√≥n real del robot, calcula la distancia y √°ngulo a cada una de 
% las balizas, y a√±ade ruido para simular la imprecisi√≥n del sensor. Devuelve 
% tanto la lectura real como la lectura con ruido; tambi√©n devuelve un vector 
% columna indicando si cada una de las balizas est√°n visibles o no
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/update_figure.m update_figure>: 
% Actualiza la figura que representa el mapa, la posici√≥n real del robot (x negra), 
% la posici√≥n odom√©trica (+ azul), la estimaci√≥n LSE (c√≠rculo verde) o cuando 
% hay menos de 3 balizas a la vista (c√≠rculo rojo)
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/est_lse.m est_lse>: 
% Estima la posici√≥n por m√≠nimos cuadrados. El c√≥digo es similar al que se proporcion√≥ 
% en la pr√°ctica, salvo por que se utilizan las estructuras Robot y Mapa. La funci√≥n 
% tambi√©n recibe las lecturas del sensor (zNoisy) y qu√© balizas son visibles y 
% se pueden utilizar en el algoritmo (bVisible)
% * <https://github.com/rpluma/cnprrb/blob/main/t01localiz/est_fp.m est_fp>: 
% Estima la posici√≥n por filtro de part√≠culas. Esta funci√≥n recibe como entrada 
% la distancia y √°ngulo a todas las balizas (con ruido), aunque en cada invocaci√≥n 
% s√≥lo se selecciona una baliza
%% 
% El enfoque orientado a objetos se ha implementado reutilizando el c√≥digo desarrollado 
% en el enfoque procedural. Hay una √∫nica clase <https://github.com/rpluma/cnprrb/blob/main/t01localiz/Robot.m 
% Robot> que contiene los siguientes m√©todos:
%% 
% * Constructor: Crea el robot y lo ubica en su posici√≥n inicial de un mapa 
% con un tama√±o determinado y en el cual se ubican un determinado n√∫mero de balizas 
% de forma aleatoria
% * Sense: Calcula la distancia y el √°ngulo entre la posici√≥n real del robot 
% y cada una de las balizas, a√±ade ruido a las mediciones para simular la precisi√≥n 
% del sensor, y determina que¬¥balizas son visibles seg√∫n el rango del sensor y 
% cu√°l se utilizar√° al azar para el filtro de part√≠culas
% * LSE: Estima la posici√≥n del robot por m√≠nimos cuadrados si hay 3 o m√°s balizas 
% visibles o compone la acci√≥n sobre la √∫ltima estimaci√≥n en caso contrario
% * FP: Estima la posici√≥n por filtro de part√≠culas y selecciona las mejores 
% part√≠culas para la siguiente iteraci√≥n
% * Plot: Grafica las posiciones real y odom√©trica del robot desde la primera 
% iteraci√≥n hasta el punto actual. Opcionalmente grafica las estimaciones LSE 
% y/o FP, as√≠ como la posici√≥n de las part√≠culas en la √∫ltima iteraci√≥n
% * Move: Mueve todas las posiciones del robot (real, odom√©trica, posiciones 
% estimadas por LSE y por FP, y posiciones de las part√≠culas) de acuerdo con la 
% petici√≥n uOdom; opcionalmente corrige la posici√≥n moviendo el robot hacia la 
% posici√≥n odom√©trica.
% * PlotErrors: Genera las distintas gr√°ficas para representar los errores.
%% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
%% 1 - LSE
% Realizamos los ejercicios, incluyendo algunos que no son puntuables, para 
% demostrar la funcionalidad implementada.
% 1.0 Modelo de odometr√≠a
% _Dise√±a un programa que iterativamente comande un robot para  seguir una trayectoria 
% en forma de cuadrado de lado 10 metros_
% 
% _Modifica el ejercicio 2 para que la acci√≥n de control se vea afectada por 
% ruido. Para ello considera la matriz de covarianzas Œ£ùë¢ùë° ._

clc; clear all; close all;
mapSize=15;numLmarks=10;tp=0.1;p0=[5;-5;pi/2];
seed=5; % 5, 11, 13, 18 18
rng(seed); 

figure;
rng(seed); 
r=Robot(mapSize, numLmarks, p0);
for i = 1:44
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(false, false, false);
%% 
% *Observaciones*
%% 
% * Seg√∫n la pose odom√©trica, el robot describe un cuadrado perfecto. 
% * Sin embargo, la figura que describe el robot en la realidad dista mucho 
% de ser un cuadrado, y esto se debe a que los actuadores a√±aden ruido
% * El ruido en el √°ngulo tiene mucha influencia sobre el resultado final, ya 
% que a partir de ese punto los errores se propagan
% 1.1.a Implementaci√≥n LSE
% _Analiza y completa el c√≥digo que se adjunta con esta pr√°ctica (cypr_localization_LSE.mlx) 
% para que un robot, el cual es comandado a seguir un cuadrado de lado 10m, sea 
% capaz de estimar su posici√≥n real en cada iteraci√≥n_
% 
% _Emplea  las medidas de distancia a 5 landmarks distribuidos en el entorno 
% de trabajo, y considera una matriz de covarianza del  sensor con valores bajos 
% (std_d=0.05 )_

figure;
rng(seed); 
r=Robot(mapSize, 5, p0); % 5 landmarks
r.senRange=[100;2*pi];   % sensor sin limmitaci√≥n efectiva de distancia/√°ngulo
r.senSigma=[0.05;0.05];  % sensor m√°s preciso (5 cm y 9¬∫)
for i = 1:44
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(true, false, false);
%% 
% *Observaciones*
%% 
% * La figura real que describe el robot es muy distinta a la del ejercicio 
% anterior por el cambio en el n√∫mero de balizas, ya que el generador de n√∫meros 
% aleatorios ya no proporciona los mismos valores
% * Aunque la figura dista mucho de ser un cuadrado, la estimaci√≥n de la posici√≥n 
% real es muy fiable (estrellas casi siempre dentro de los c√≠rculos)
% * En la configuraci√≥n del robot (r.senRange), se ha establecido un rango de 
% 100m y un √°ngulo de 360¬∫ para que el sensor se comporte como si no tuviera limitaciones
% 1.1.b Implementaci√≥n LSE
% _Vuelve a repetirlo con valores m√°s altos (std_d=0.5)._

figure;
rng(seed); 
r=Robot(mapSize, 5, p0);    % 5 landmarks
r.senRange=[100;2*pi];      % sensor sin limmitaci√≥n
r.senSigma=[0.5;.5];        % sensor poco preciso
for i = 1:44
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(true, false, false);
%% 
% *Observaciones*
%% 
% * La figura real que describe el robot es id√©ntica al caso anterior porque 
% seguimos utilizando la misma semilla.
% * Las estimaciones que realiza LSE son menos precisas, aunque aproximan bastante 
% bien la posici√≥n del robot
% 1.2. Ejercicio puntuable - LSE
% _Los sensores reales presentan ciertas limitaciones  f√≠sicas en cuanto al 
% rango y campo de visi√≥n. Modifica el ejercicio anterior para  contemplar que 
% el sensor s√≥lo proporciona medidas en un rango limitado ùëüùëô y una  orientaci√≥n 
% limitada ¬±ùõº con respecto a la pose del robot. Podr√≠a darse el caso que no  
% existieran landmarks en el campo de visi√≥n del sensor, con lo que el robot no 
% dispondr√≠a de informaci√≥n sensorial en una iteraci√≥n._
% 
% _Aumenta el n√∫mero de Landmarks a 10 y  considera el caso particular de un 
% sensor con  un rango m√°ximo de 20m de alcance, y un FOV  de ¬±60¬∫_
% LSE con 3 o m√°s balizas visibles
% Representamos los 18 primeros movimientos del robot en los que hay al menos 
% 3 balizas visibles desde la posici√≥n real del robot

figure;
rng(seed); 
r=Robot(mapSize, 10, p0);   % 10 landmarks
r.senRange=[20;60*pi/180];  % rango de 20 metros y 60¬∫
r.senSigma=[0.05;.05];      % sensor muy preciso
for i = 1:18
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(true, false, false);
%% 
% *Observaciones*
%% 
% * Anque el enunciado no lo especifica, hemos optado por versi√≥n m√°s fiable 
% del sensor
% * Aunque las balizas est√°n siempre en las mismas posiciones, s√≥lo se etiquetan 
% las que est√°n en el rango de visi√≥n del robot desde la posici√≥n real.
% * En todo el trazado hasta el punto de la figura, la estimaci√≥n se realiza 
% con 3 o m√°s balizas a la vista, pero la baliza L9 deja de estar visible para 
% la siguiente estimaci√≥n, que se tiene que realizar por otro m√©todo a partir 
% de ese punto.
% Tratamiento con menos de 3 balizas
% _Indica claramente en la memoria como tratas  el caso de no tener suficientes 
% observaciones,  y mu√©stralo en las gr√°ficas de posici√≥n y de  error. A√±ade/explica 
% solo la parte del c√≥digo  que has modificado._ 
% 
% Como con dos balizas no podemos utilizar LSE, partiendo de la √∫ltima posici√≥n 
% estimada, componemos la actualizaci√≥n odom√©trica sobre la √∫ltima estimaci√≥n

r=r.Move([1;0;0], false);
r.Plot(true, false, false);
a = annotation('arrow'); a.Parent = gca; a.Position = [-4.2, 5,-1,0];
a = annotation('arrow'); a.Parent = gca; a.Position = [-4.2,-2.8,-1,0];
%% 
% *Observaciones*
%% 
% * En este caso, el robot se est√° desplazando hacia abajo pero "piensa" que 
% se est√° moviendo hacia la derecha.
% * La nueva posici√≥n se estima moviendo hacia la derecha la estimaci√≥n anterior, 
% pero esto aleja la estimaci√≥n y la posici√≥n real, ya que los √°ngulos de la pose 
% odom√©trica y de la pose real son muy distintos.
% * En la medida en que los √°ngulos difieran, la estimaci√≥n por este m√©todo 
% ser√° m√°s o menos fiable.
% Resultado final con LSE
% Completamos el cuadrado para evaluar el resultado final

for i = 20:44
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(true, false, false);
%% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% *Observaciones*
%% 
% * Las estimaciones son fiables cuando hay 3 o m√°s balizas visibles, lo cual 
% ocurre en la mayor parte del recorrido.
% * Cada vez que el robot deja de tener 3 balizas a la vista y que el √°ngulo 
% de la pose real difiere significativamente del de la pose odom√©trica, la estimaci√≥n 
% "se pierde" porque mueve el robot en la direcci√≥n equivocada
% * La primera vez que ocurre, la estimaci√≥n "camina" hacia la izquierda porque 
% el robot deber√≠a estar en la parte superior del cuadrado, aunque el desplazamiento 
% real es hacia abajo
% * Del mismo modo, cuando se vuelve a perder en el lado inferior del cuadrado 
% el robot sigue caminando hacia abajo porque en ese punto deber√≠a estar bajando 
% por el lado izquierdo del cuadrado
% * Cuando el robot recupera la visi√≥n de 3 o m√°s balizas, la estimaci√≥n se 
% corrige por completo
%% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
%% 2 Filtro de Part√≠culas
% 2.1 Implementaci√≥n del filtro de part√≠culas
% _En este ejercicio vamos a implementar paso a paso un sistema de  localizaci√≥n 
% basado en filtro de part√≠culas._
% 
% _En este ejercicio vamos a implementar paso a paso un sistema de  localizaci√≥n 
% basado en filtro de part√≠culas. Para ello se recomienda seguir los  siguientes 
% pasos:_ 
% 
% _*a. Medida Sensorial:* Utilizando un mapa de landmarks como el empleado en 
% los  ejercicios anteriores, implementa ahora una funci√≥n que tome como entrada 
% la  pose del robot, seleccione aleatoriamente un solo landmark de entre todos 
% los  disponibles, y devuelva la observaci√≥n del sensor a dicho landmark. Dicha  
% observaci√≥n estar√° compuesta por las medidas de distancia y √°ngulo entre el 
% robot  y el landmark seleccionado, afectadas por el ruido del sensor siguiendo 
% su modelo  de ruido en base a la matriz de covarianza_
% 
% El m√©todo Sense implementa esta funcionalidad:
%%
% 
%   for i = 1:r.numLmarks
%     % c√°lculo de distancia y √°ngulo
%     r.zTrue(:, i) = dist_angle(r.pTrue, r.posLmarks(:, i));
%     % a√±adir ruido a las lecturas del sensor
%     r.zNoisy(:, i) = r.zTrue(:,i) + r.senSigma .*randn(2, 1);
%     % selecci√≥n de sensores visibles (utilizado en LSE)
%     r.bVisible(i) = r.zTrue(1,i)<=r.senRange(1) && abs(r.zTrue(2,i)) <= r.senRange(2));        
%   end
%   % n√∫mero de sensores visibles (utilizado en LSE)
%   r.nVisible = sum(r.bVisible);
%   % baliza elegida en cada paso
%   r.iLmFP = randperm(r.numLmarks, 1); 
%
%% 
% 
% 
% _*b. Acci√≥n de Control:* Programa el movimiento del robot como en pr√°cticas  
% anteriores, buscando realizar un cuadrado de lado 10m, y estando las acciones 
% de  control afectadas por cierto ruido aleatorio en base a_ $\Sigma_s$
% 
% _En este punto, tendremos la pose odom√©trica (xOdom), es decir, donde el robot  
% cree que est√°, la pose real (xTrue), es decir, donde el robot est√° realmente 
% (esta  pose, aunque la simularemos en este ejercicio, es desconocida por el 
% robot y es la  que se quiere estimar con el sistema de localizaci√≥n), y deberemos 
% generar un  n√∫mero de N poses candidatas (samples), dadas por las part√≠culas 
% del filtro que  estamos implementando. Considerar N=100_
% 
% Esta funcionalidad se ha implementado dentro del m√©todo Move:
%%
% 
%   % acci√≥n de control del robot afectado por el ruido aleatorio del actuador
%   r.pTrue = comp_noisy(r.pTrue, uOdom, r.actSigma);
%   % la posici√≥n odom√©trica sigue el cuadrado perfecto (comp_odom)
%   r.pOdom = comp_odom(r.pOdom, uOdom);
%   % las part√≠culas tambi√©n se muevoen pero tambi√©n con ruido (comp_noisy)
%   r.pPart = comp_noisy(r.pPart, uOdom, r.actSigma);
%
%% 
% 
% 
% _*c. Actualizaci√≥n de Poses:* Programa que en cada iteraci√≥n el robot realiza 
% una acci√≥n  de control (para avanzar en el cuadrado) y recibe una medici√≥n del 
% sensor a un  landmark aleatorio del mapa (usando la funci√≥n del apartado anterior). 
% Con esta  informaci√≥n, deberemos actualizar las poses xOdom y xTrue, as√≠ como 
% las poses de  todas las samples (considerando para cada una de ellas una muestra 
% de ruido  diferente). Visualiza en cada iteraci√≥n estas poses_
% 
% Esta funcionalidad est√° implementada en el m√©todo Move (ver apartado anterior). 
% Adicionalmente se ha implementado un m√©todo para visualizar el robot desde la 
% posici√≥n inicial hasta el √∫ltimo paso.
% 
% _*d. Pesos del FP*: Para poder estimar la pose real del robot a partir de 
% las N part√≠culas  del filtro, partimos de que la posici√≥n de los landmarks es 
% conocida en el mapa. El  objetivo ahora es poder discernir cuales de las N part√≠culas 
% actuales representan  adecuadamente la pose real del robot y cu√°les no (recuerda 
% que la pose xTrue es  desconocida, y por tanto no se puede usar en los c√°lculos). 
% Para ello, asocia a cada  part√≠cula un peso W(i) que indique c√≥mo de probable 
% es la pose que representa  dicha part√≠cula con respecto a las observaciones 
% que toma el robot. Inicialmente  consideraremos que todas las part√≠culas tienen 
% el mismo peso, y por comodidad  impondremos que la suma de todos los pesos resulte 
% 1 en todo momento  (normalizaci√≥n)_
% 
% Esta funcionalidad se ha implementado dentro del m√©todo FP. En lugar de la 
% expresi√≥n sugerida en el enunciado (comentada abajo) se ha optado por una funci√≥n 
% que no devuelve rangos tan extremos
%%
% 
%   % utilizamos la baliza elegida al azar (slm=Selected LandMark)
%   slm = r.posLmarks(:, r.iLmFP); 
%   
%   % utilizamos la medida de distancia y √°ngulo con ruido (zNoisy)
%   z = r.zNoisy(: , r.iLmFP); 	
%   
%   % inicializaci√≥n de pesos
%   W = zeros(1, r.fpPart);
%   
%   % inversa de matriz de covarianza del sensor
%   CovInv = inv(diag(r.senSigma).^2);
%   
%   for i = 1:r.fpPart
%       % predicci√≥n de distancia y √°ngulo desde la part√≠cula a la baliza
%       zPred = dist_angle(r.pPart(:,i), slm);
%      
%       % Peso = 1/error entre predicci√≥n y de part√≠cula y medida observada    
%       W(i) = 1/((z-zPred)'*CovInv*(z-zPred)+0.001);
%       % W(i)=exp(-0.5*(zTrue-zPred)'*r.sensorCovInv*(zTrue-zPred))+0.01;
%   end
%   % normalizaci√≥n de pesos
%   W = W/sum(W);
%
%% 
% _*e. Selecci√≥n de Part√≠culas:* Hasta ahora mantenemos el mismo grupo de N 
% part√≠culas,  actualizando su pose en cada iteraci√≥n y recalculando sus pesos. 
% No obstante,  seguimos manteniendo de una iteraci√≥n a otra todas las part√≠culas 
% sin importar sus  pesos, con lo que observamos como las part√≠culas se van dispersando 
% y alejando de  la posici√≥n real del robot (al igual que ocurr√≠a en la pr√°ctica 
% 1, por efecto del ruido  en la acci√≥n de control)._
% 
% La selecci√≥n se realiza con el m√©todo propuesto
% 
% _*f. Estimaci√≥n de la pose del robot (xEst):* Una vez hemos seleccionado las 
% part√≠culas  con mejor peso, ya tenemos implementado el filtro de part√≠culas. 
% Tan solo nos falta  determinar, en base a las part√≠culas actuales y sus pesos,_
% 
% En el m√©todo Move se han implementado los 3 m√©todos sugiredos, aunque s√≥lo 
% se est√° utilizando el √∫ltmo porque se ha observado que es el m√°s robusto.
%%
% 
%   % pose de la mejor part√≠cula
%   if r.fpMethod == "best" 
%     [wMax, iMax] = max(W);
%     r.pEstF = r.pPart(:, iMax); 
%   
%   % media de poses de part√≠culas
%   elseif r.fpMethod == "mean" 
%    r.pEstF(1) = sum(r.pPart(1, :));
%    r.pEstF(2) = sum(r.pPart(2, :));        
%    r.pEstF(3) = circ_mean(r.pPart(3, :)');
%   
%   % media ponderada de poses
%   elseif r.fpMethod == "weight" 
%    r.pEstF(1) = sum(r.pPart(1, :).*W);
%    r.pEstF(2) = sum(r.pPart(2, :).*W);
%    r.pEstF(3) = circ_mean(r.pPart(3, :)', W');
%   end	
%
% 2.2.a Filtro sin correcciones
% _Una vez tengas implementado y funcionando  correctamente el filtro de part√≠culas 
% del ejercicio anterior, vamos a corregir la pose del  robot. Sabemos que el 
% robot se ‚Äúdesv√≠a‚Äù de su trayectoria deseada (el cuadrado de  lado 10m), pero 
% gracias a la localizaci√≥n del FP ya sabemos d√≥nde estamos realmente.  Implementa 
% en este ejercicio, que cada 5 iteraciones se a√±ade un ‚Äúpaso extra‚Äù para  corregir 
% la pose del robot y hacer que vuelva al cuadrado._
% _Funcionamiento del filtro_
% _Muestra inicialmente una captura en la que se aprecie el correcto  funcionamiento 
% del filtro (sin correcciones)._ 

figure;
rng(seed); 
r=Robot(mapSize, 10, p0);   % 10 landmarks
r.senRange=[20;60*pi/180];  % rango de 20 metros y 60¬∫
r.senSigma=[0.05;.05];      % sensor muy preciso
for i = 1:44
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], false);
    else
        r=r.Move([1;0;0], false);
    end
end
r.Plot(false, true, true);
%% 
% *Observaciones*
%% 
% * S√≥lo se muestran las part√≠culas del √∫ltimo paso, pero para ver la evolici√≥n 
% del movimento de las part√≠culas se puede invocar al m√©todo de visualizaci√≥n 
% en cada paso.
% * La posici√≥n real del robot es id√©ntica a la del ejercicio anterior porque 
% en cada paso del robot se est√°n calculando ambas estimaciones y solo al final 
% se decide cu√°l de ellas mostrar.
% * Con una sola baliza elegida al azar, el filtro de part√≠culas estima bastante 
% bien la posici√≥n del robot, y no tiene el problema de "desorientaci√≥n" que observ√°bamos 
% con LSE, ya que ahora disponemos de una estimaci√≥n del √°ngulo de la pose que 
% con LSE no ten√≠amos.
% Error en la posici√≥n
% _Muestra una gr√°fica del error  entre xTrue y xEst a lo largo de las iteraciones, 
% tanto error en posici√≥n como en  orientaci√≥n. Comenta los resultados._

r.PlotErrors(true, false, false, false);
%% 
% *Observaciones*
% 
% La figura muestra la comparativa de los 3 errores (odom√©trico, LSE y FP) que 
% se han calculado a partir de los mismos datos
%% 
% * El error odom√©trico est√° midiendo la distancia entre la posici√≥n que quer√≠amos 
% tener y la posici√≥n real del robot. Este error depende de la fiabilidad de los 
% actuadores, sobre todo en los giros. A partir del tercer paso el robot empieza 
% a desviarse hacia la izquierda y este error se va propagando hasta el final. 
% La media del error depende mucho de la trayectoria seguida (imprevisible), y 
% en este caso ha resultado ser de 5 metros.
% * El error de la estimaci√≥n con LSE est√° calculando la distancia entre la 
% estimaci√≥n realizada y la posici√≥n real. La media del error es muy media cercana 
% a cero cuando hay 3 o m√°s balizas en el rango de visi√≥n, pero se dispara cada 
% vez que el robot "se pierde" (en los pasos 19, 25 y 41) llegando a estar por 
% encima de 6 metros. Aunque el error es bajo, este m√©todo no permite hacer correcciones 
% porque no hemos estimado el √°ngulo de la pose.
% * El error con la estimaci√≥n del FP es an√°logo al medido con LSE. Aunque el 
% error es mayor que el obtenido con LSE (medio metro de promedio), hay que tener 
% en cuenta que s√≥lo se ha utilizado una baliza, y que adem√°s nos permite hacer 
% correcciones porque FP proporciona una estimaci√≥n del √°ngulo de la pose.
% 2.2.b Filtro con correcciones
% Captura de correcciones cada 5 pasos
% _Luego a√±ade otra captura donde se aprecien las correcciones cada 5 pasos  
% implementados en este ejercicio._ 
% 
% Para implementar las correcciones a√±adimos el par√°metro variable bFix al m√©todo 
% Move.

figure; set(gcf,'Visible','on');
rng(seed); 
r=Robot(mapSize, 10, p0); % 5 landmarks
r.senRange=[20;60*pi/180]; % rango de 20 metros y 60¬∫
r.senSigma=[0.05;.05]; % sensor poco preciso
for i = 1:44
    bFix = mod(i,5)==0;
    if mod(i,11) == 0
        r=r.Move([0;0;pi/2], bFix);
    else
        r=r.Move([1;0;0], bFix);
    end
    r.Plot(false, true, true);
    pause(0.5)
end
%% 
% *Observaciones*
%% 
% * Aunque el robot dibuja una figura muy distinta a un cuadrado, el resultado 
% se ajusta mejor que cuando no hab√≠a correcciones.
% * La correcci√≥n m√°s visible se produce llegando a la esquina superior derecha 
% del cuadrado, y se aprecia que el robot vuelve a la posici√≥n odom√©trica con 
% bastante exactitud
% Error de posici√≥n y orientaci√≥n
% En este caso, muestra las gr√°ficas de error  entre xEst y xOdom (para que 
% se aprecie que cada 5 pasos el error debe  hacerse muy peque√±o), tanto de posici√≥n 
% como de orientaci√≥n. 

r.PlotErrors(false, false, true, false); 
%% 
% *Observaciones*
%% 
% * El error odom√©trico se ha reducido a menos de un metro en promedio; esto 
% se debe a que las correcciones redirigen el robot a la posici√≥n requerida.
% * El error en la posici√≥n estimada por el filtro es del mismo orden de magnitud 
% que cuando no se hac√≠an correciones.
% * El error en el √°ngulo se ha calculado como diferencia entre la pose real 
% del robot y la pose estimada. Hay oscilaciones significativas (p. ej. cerca 
% de +40¬∫ en el paso 19 y cerca de -30¬∫ en el paso 4), pero en general los √°ngulos 
% coinciden bastante bien.
%% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
%% Ap√©ndice - Ejecuci√≥n manual
% Para probar el buen funcionamiento del robot, hemos definido un script que 
% permite ejecutar movimientos simples eligiendo en cada caso qu√© queremos que 
% haga el robot
%% 
% * Inicializaci√≥n: empezamos desde cero utilizando siempre la misma semilla 
% para que las pruebas sean reproducibles
% * Avanzar: el robot avanza un metro sin corregir su pose
% * Corregir sin avanzar: la posici√≥n odom√©trica se mantiene pero el robot se 
% desplaza hacia ella desde su estimaci√≥n FP y ajusta su √°ngulo para que siga 
% le misma orientaci√≥n
% * Giro a la izquierda: el robot gira 90 grados a la izquierda y despu√©s avanza 
% una posici√≥n permitiendo as√≠ ver que efectivamente ha girado como deseamos
% * Giro a la derecha: an√°loga al giro a la izquierda
%% 
% Las figuras se van actualizando sobre la anterior, por lo que cada una representa 
% el estado del robot la √∫ltima vez que se ejecut√≥ el script
% Inicializaci√≥n

clc; clear all; close all;
mapSize=15;numLmarks=10;tp=0.1;p0=[5;-5;pi/2];
seed=5; % 5, 11, 13, 18 18
rng(seed); 
figure
r=Robot(mapSize, numLmarks, p0);
r.Plot(true, true, true);
% Avanzar

r=r.Move([1;0;0], false);
r.Plot(true, true, true);
% Corregir sin avanzar

r=r.Move([0;0;0], true);
r.Plot(true, true, true);
% Giro a la izquierda

r=r.Move([0;0;pi/2], false);
r=r.Move([1;0;0], false);
r.Plot(true, true, true);
% Giro a la derecha

r=r.Move([0;0;-pi/2], false);
r=r.Move([1;0;0], false);
r.Plot(true, true, true);