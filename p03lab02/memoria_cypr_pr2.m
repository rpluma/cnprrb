%% Memoria de ejercicios puntuables de localizaciÃ³n
% 
% 
% Se entregarÃ¡ un Ãºnico archivo comprimido (PR2.zip), conteniendo una Ãºnica 
% memoria en PDF (memoria_cypr_pr2.pdf) con indicaciÃ³n de los ejercicios que se 
% han resuelto, comentarios sobre el mismo y capturas de pantalla que justifiquen 
% el funcionamiento (no aÃ±adir el cÃ³digo a la memoria). Finalmente, un archivo 
% Matlab en formato live_script (*.mlx) por cada ejercicio realizado.
%% 
% * Alumno: Ricardo Panero Lamothe
% * Asignatura: Control y ProgramaciÃ³n de Robots
% * Curso: 2022/23
% * Plazo de entrega: 12-dic-2022
%% Ejercicio puntuable - LSE
% Enunciado
% Los sensores reales presentan ciertas limitaciones  fÃ­sicas en cuanto al rango 
% y campo de visiÃ³n. Modifica el ejercicio anterior para  contemplar que el sensor 
% sÃ³lo proporciona medidas en un rango limitado ğ‘Ÿğ‘Ÿğ‘™ğ‘™ y una  orientaciÃ³n limitada 
% Â±ğ›¼ğ›¼ con respecto a la pose del robot. PodrÃ­a darse el caso que no  existieran 
% landmarks en el campo de visiÃ³n del sensor, con lo que el robot no dispondrÃ­a 
% de informaciÃ³n sensorial en una iteraciÃ³n
% 
% Aumenta el nÃºmero de Landmarks a 10 y  considera el caso particular de un 
% sensor con  un rango mÃ¡ximo de 20m de alcance, y un FOV  de Â±60Âº
% 
% Indica claramente en la memoria como tratas  el caso de no tener suficientes 
% observaciones,  y muÃ©stralo en las grÃ¡ficas de posiciÃ³n y de  error. AÃ±ade/explica 
% solo la parte del cÃ³digo  que has modificado
% SoluciÃ³n
% Definimos la variable Mapa como un diccionario para almacenar todos los campos 
% correspondientes y definimos la funciÃ³n crear_landmarks para inicializar los 
% landmarsk de forma aleatoria

% inicializaciÃ³n del script
clc;
clear all; 
%addpath(['auxmatlab/aux_functions'], 'auxmatlab/aux_functions_prob', 'p03lab02');

% diccionario para almacenar los valores referentes al mapa
Mapa={};
Mapa.nLandmarks = 10;
Mapa.Size = 50;      

% creaciÃ³n de landmarks aleatorios
Mapa.Landmarks = crear_landmarks(Mapa);
%% 
% Definimos la funciÃ³n leer_sensores que devuelve las distancias teniendo en 
% cuenta el rango del sensor y orientaciÃ³n del robot. La funciÃ³n colorea en verde 
% los sensores que quedan en rango

% inicializaciÃ³n de parÃ¡metros del robot
Robot={};
Robot.xTrue=[-5 -5 pi/2]'; % posiciÃ³n inicial del robot
Robot.xOdom=Robot.xTrue; % posiciÃ³n odomÃ©trica 
Robot.xEst = Robot.xTrue; % posiciÃ³n estimada con LSE
Robot.inc_x = 1;
Robot.inc_phi = pi/2;
Robot.u_stdx = 0.5;
Robot.u_stdy = 0.5;
Robot.u_stdphi = 0.5*pi/180;
Robot.std = diag([Robot.u_stdx, Robot.u_stdy, Robot.u_stdphi]);
Robot.U = Robot.std .^ 2;

% incializaciÃ³n de parÃ¡metros del sensor
Sensor={};
Sensor.var_d=0.05^2; % varianza del sensor de distancia
Sensor.std_d = sqrt(Sensor.var_d); % desviaciÃ³n tÃ­pica
Sensor.rango=20; % rango lineal del sensor en metros
Sensor.alfa=90; % rango angular (FOV=+/-alfa) en grados

% lectura de distancias
Sensor.z = leer_distancias(Mapa, Robot, Sensor);
%% 
% Realizamos el cuadrado teniendo en cuenta lo siguiente:
%% 
% # Inicializamos variables antes de entrar en el bucle
% # Para cada paso del bucle, movemos en lÃ­nea recta o giramos en funciÃ³n del 
% nÃºmero de paso
% # La posiciÃ³n odomÃ©trica la calculamos sin errores
% # La posiciÃ³n real la simulamos para que aÃ±ada ruido
% # Leemos los sensores que estÃ¡n en rango
% # Si hay 3 o mÃ¡s sensores en rango, estimamos la posiciÃ³n con LSE
% # En caso contrario, actualizamos la estimaciÃ³n anterior con la acciÃ³n odomÃ©trica
% # Actualizamos errores y dibujamos el robot

% 1 Incializamos variables
num_loops = 44;
loc_error = zeros(num_loops,1);
odo_error = zeros(num_loops,1);
num_sensors = zeros(num_loops,1);
Lse={};
Lse.max_iter = 100;
Lse.tolerance = 1.0e-09;  

for i=1:num_loops
    % 2 decidimos si avanzar o girar
    if (mod(i,11)==0)
        u=[0 0 Robot.inc_phi]'; % giro en cada esquina
    else
        u=[Robot.inc_x 0 0]'; % lÃ­nea recta en el resto
    end

    % 3 cÃ¡lculo de la posiciÃ³n odomÃ©trica sin errores
    Robot.xOdom = pose_comp(Robot.xOdom, u);

    % 4 aÃ±adimos ruido a la acciÃ³n para simular la actuaciÃ³n ruidosa
    noise = Robot.std*randn(3,1);
    uNoisy = pose_comp(u, noise);
    Robot.xTrue = pose_comp(Robot.xTrue, uNoisy);

    % 5 Lectura de sensores en rango
    Sensor.z = leer_distancias(Mapa, Robot, Sensor);
    
    if sum(Sensor.z>0) >= 3 % los sensores que no estÃ¡n en rango devuelven distancia negativa
        % 6 Si hay 3 o mÃ¡s sensores en rango estimamos con LSE
        Robot.xEst = estimar_posicion(Mapa, Robot, Sensor, Lse);      
    else        
        % 7 Si hay menos de 3 sensores, actualizamos con la acciÃ³n ruidosa
        Robot.xEst = pose_comp(Robot.xEst, u);
    end


    % 8 Actualizamos errores y dibujamos
    loc_error(i) = sqrt((Robot.xTrue(1)-Robot.xEst(1))^2+(Robot.xTrue(2)-Robot.xEst(2))^2);    
    odo_error(i) = sqrt((Robot.xTrue(1)-Robot.xOdom(1))^2+(Robot.xTrue(2)-Robot.xOdom(2))^2);
    num_sensors(i) = length(Sensor.z(Sensor.z>1));
    plot(Robot.xTrue(1),Robot.xTrue(2),'bo');   % Real Position (Ground Truth with Noise)
    plot(Robot.xOdom(1),Robot.xOdom(2),'r.');   % Odometry or ideal (Noise-free)
    pause(0.1);
end
%% 
% Generamos las grÃ¡ficas finales

avg_loc_error = mean(loc_error);
avg_odo_error = mean(odo_error);
avg_num_sensors = mean(num_sensors);

figure(2);
set(gcf,'Visible','on');
subplot(311); 
plot(loc_error,'r'); 
hold on; 
line([1 size(loc_error,1)],[avg_loc_error avg_loc_error]); 
title('Position Errors with localization');
xlabel('Iteration Number');
ylabel('Error (m)');

subplot(312); 
plot(odo_error,'k'); 
hold on; 
line([1 size(odo_error,1)],[avg_odo_error avg_odo_error]); 
title('Odometric error');
xlabel('Iteration Number');
ylabel('Error (m)');

subplot(313); 
plot(num_sensors,'k'); 
hold on; 
line([1 size(num_sensors,1)],[avg_num_sensors avg_num_sensors]); 
title('Sensors in range');
xlabel('Iteration Number');
ylabel('# Sensors');

%%
x
%%
x
%%

%% x
%% Ejercicio puntuable - FP
% ImplementaciÃ³n del filtro de partÃ­culas
% a) Medida sensorÃ­al
% Utilizando un mapa de landmarks como el empleado en los  ejercicios anteriores, 
% implementa ahora una funciÃ³n que tome como entrada la  pose del robot, seleccione 
% aleatoriamente un solo landmark de entre todos los  disponibles, y devuelva 
% la observaciÃ³n del sensor a dicho landmark. Dicha  observaciÃ³n estarÃ¡ compuesta 
% por las medidas de distancia y Ã¡ngulo entre el robot  y el landmark seleccionado, 
% afectadas por el ruido del sensor siguiendo su modelo  de ruido en base a la 
% matriz de covarianza

% Inicializamos el mapa
close all;
clear all;
Mapa={};
Mapa.nLandmarks = 7;
Mapa.Size = 20;      
Mapa.Landmarks = crear_landmarks(Mapa);

% Inicializamos el robt
Robot={};
Robot.xTrue=[5 -5 pi/2]' % posiciÃ³n inicial del robot
Robot.xOdom=[5 -5 pi/2]';
Robot.CovSensor = diag([0.5^2 (0.5*pi/180)^2]);

% Leemos la observaciÃ³n 
observacion=leer_sensor(Mapa, Robot)
% b) AcciÃ³n de control
% Programa el movimiento del robot como en prÃ¡cticas  anteriores, buscando realizar 
% un cuadrado de lado 10m, y estando las acciones de  control afectadas por cierto 
% ruido aleatorio en base a la matriz de covarianza de acciones
% 
% En este punto, tendremos la pose odomÃ©trica (xOdom), es decir, donde el robot  
% cree que estÃ¡, la pose real (xTrue), es decir, donde el robot estÃ¡ realmente 
% (esta  pose, aunque la simularemos en este ejercicio, es desconocida por el 
% robot y es la  que se quiere estimar con el sistema de localizaciÃ³n), y deberemos 
% generar un  nÃºmero de N poses candidatas (samples), dadas por las partÃ­culas 
% del filtro que  estamos implementando. Considerar N=100.

%Robot.plot = drawrobot(Robot.xTrue, 'b');
Robot.u_avance = [1 0 0]'; % accion de avance sin ruido
Robot.u_giro = [0 0 pi/2]'; % acciÃ³n de giro a la izquierda
Robot.CovU = diag([0.5^2 0.5^2 (0.5*pi/180)^2]); % covarianzas
Robot.Particles = 100;
Robot.xProb = zeros(3, Robot.Particles);

for i=1:44
    if mod(i,11)==0
        u=Robot.u_giro;
    else
        u=Robot.u_avance;
    end
    % posiciÃ³n odomÃ©trica
    Robot.xOdom=pose_comp(Robot.xOdom, u);
    plot(Robot.xOdom(1), Robot.xOdom(2), 'r.');

    % posiciÃ³n real afectada por el ruido
    noise=sqrt(Robot.CovU)*randn(3, 1);
    Robot.xTrue=pose_comp(Robot.xTrue, pose_comp(u, noise));
    plot(Robot.xTrue(1), Robot.xTrue(2), 'k.');
    
    % lectura de un sensor aleatorio (ver apartado c)
    observacion=leer_sensor(Mapa, Robot)

    % generaciÃ³n de partÃ­culas
    for j=1:Robot.Particles
        noise=sqrt(Robot.CovU)*randn(3, 1);
        Robot.xProb(:,j)=pose_comp( ...
            Robot.xProb(:,j), pose_comp(u, noise));
    end
    if (mod(i, 11)==0)
        part=plot(Robot.xProb(1,:), Robot.xProb(2,:), '.');
        set(part, 'MarkerSize', 5, 'Color', [rand rand rand]);
    end

    % pesos del FP (ver apartado d)
    
end

% c) ActualizaciÃ³n de poses
% Programa que en cada iteraciÃ³n el robot realiza una acciÃ³n  de control (para 
% avanzar en el cuadrado) y recibe una mediciÃ³n del sensor a un  landmark aleatorio 
% del mapa (usando la funciÃ³n del apartado anterior). Con esta  informaciÃ³n, deberemos 
% actualizar las poses xOdom y xTrue, asÃ­ como las poses de  todas las samples 
% (considerando para cada una de ellas una muestra de ruido  diferente). Visualiza 
% en cada iteraciÃ³n estas poses.
% 
% 
% 
% observacion=leer_sensor(Mapa, Robot)
% d) Pesos del FP
% Para poder estimar la pose real del robot a partir de las N partÃ­culas  del 
% filtro, partimos de que la posiciÃ³n de los landmarks es conocida en el mapa. 
% El  objetivo ahora es poder discernir cuales de las N partÃ­culas actuales representan  
% adecuadamente la pose real del robot y cuÃ¡les no (recuerda que la pose xTrue 
% es  desconocida, y por tanto no se puede usar en los cÃ¡lculos). Para ello, asocia 
% a cada  partÃ­cula un peso W(i) que indique cÃ³mo de probable es la pose que representa  
% dicha partÃ­cula con respecto a las observaciones que toma el robot. Inicialmente  
% consideraremos que todas las partÃ­culas tienen el mismo peso, y por comodidad  
% impondremos que la suma de todos los pesos resulte 1 en todo momento  (normalizaciÃ³n).
% 
% El peso de cada partÃ­cula W(i) se actualiza en cada iteraciÃ³n atendiendo a 
% la  diferencia existente entre la medida del sensor (distancia y Ã¡ngulo afectados 
% por  ruido) que se ha obtenido en este paso (ver apartado a), y la distancia 
% y Ã¡ngulo que  hay desde la partÃ­cula considerada al landmark seleccionado. Es 
% decir: 
% 
% ğ‘Š(ğ‘–) = ğ‘“(z - zPre)
% 
% donde z es la medida sensorial que toma el robot desde el ground-truth con 
% el  sensor real (ğ‘Ÿ, ğœ™) y por tanto afectado por ruido, y zPred es la medida 
% hipotÃ©tica  que tomarÃ­a desde cada una de las partÃ­culas hasta el mismo landmark. 
% La funciÃ³n f puede ser cualquier funciÃ³n que asigne mayores valores a aquellas 
% partÃ­culas con la menor discrepancia, es decir, con z-Zpred mÃ¡s bajos. Una posible 
% funciÃ³n es: 
% 
% W(i)=exp(-0.5*(z-zPred)'*inv(Sigma_sensor)*(z-zPred))+0.001; 
% 
% Es decir, una funciÃ³n gaussiana utilizando la matriz de covarianza del modelo 
% del  sensor. Implementa esta funciÃ³n para que se vayan actualizando los pesos 
% de las  partÃ­culas en cada iteraciÃ³n.
% e) SelecciÃ³n de partÃ­culas
% f) EstimaciÃ³n de la pose del robot
%% 
% 
% Ejercicio puntuable
% a) Filtro sin correcciones
% b) Correcciones cada 5 pasos

clc;
%% PrÃ¡ctica 1. Modelo de movimiento
% En esta prÃ¡ctica vamos a implementar el modelo de movimiento basado en odometrÃ­a 
% mediante la tÃ©cnica de sampling. Comenzaremos implementando funciones bÃ¡sicas 
% que utilizaremos a lo largo de la prÃ¡ctica.
%% 1 ComposiciÃ³n de poses
% Implementa una funciÃ³n que realice la composiciÃ³n de dos poses, es decir que 
% dadas ğ‘ğ‘1 = [ğ‘¥ğ‘¥1 ğ‘¦ğ‘¦1 ğœƒğœƒ1]ğ‘‡ğ‘‡ y ğ‘ğ‘2 = [ğ‘¥ğ‘¥2 ğ‘¦ğ‘¦2 ğœƒğœƒ2]ğ‘‡ğ‘‡, devuelva 
% el resultado de la operaciÃ³n ğ‘ğ‘1 âŠ• ğ‘ğ‘2

pose_comp([-2.5 0 pi/2]', [0.2 0 -10*pi/180]')
%% 2 Modelo de odometrÃ­a
% DiseÃ±a un programa que iterativamente comande un robot para seguir una trayectoria 
% en forma de cuadrado de lado 10 metros. Para ello necesitarÃ¡s hacer uso de la 
% composiciÃ³n de poses para calcular en cada iteraciÃ³n ğ‘¥ğ‘¡ = ğ‘¥ğ‘¡âˆ’1 âŠ• ğ‘¢ğ‘¡, siendo 
% ğ‘¢ğ‘¡ = (Î”ğ‘¥ Î”y Î”ğœƒ)ğ‘‡. Considera que en cada paso el robot puede avanzar 1 metro 
% o girar 90â°. 

cuadrado(10);
%% 3 Comandando mediante velocidad lineal y angular
% Repite el ejercicio anterior (cuadrado de lado 10 metros), pero utilizando 
% en este caso una acciÃ³n de control ğ‘¢ğ‘¡ = (Vp W)ğ‘‡ formada por una velocidad 
% lineal y otra angular. 
% 
% Asume que dichos comandos de velocidad se aplican al robot cada 0.5s. Los 
% comandos se calculan de las siguientes ecuaciones:
% 
% x(Î”t) = âˆ«vP (t) cos(wt)dt
% 
% y(Î”t) = âˆ«vP (t) sin(wt)dt
% 
% Î¸ (Î”t) = âˆ« w(t) dt

cuadrado_velocidades(10);
%% 4 AÃ±adiendo ruido
% Modifica el ejercicio 2 para que la acciÃ³n de control se vea afectada por 
% ruido. Dibuja la trayectoria del robot con y sin ruido y comprueba cÃ³mo varÃ­a 
% para diferentes valores de sigma

cuadrado_ruido(10)
%% 5 Usando partÃ­culas
% Vamos a estimar la posiciÃ³n del robot en base a partÃ­culas, â€œsamplesâ€ de poses 
% probables en las que se puede encontrar el vehÃ­culo, atendiendo a la naturaleza 
% probabilÃ­stica del ruido que estamos considerando. Para ello repite el ejercicio 
% 4, mostrando la posiciÃ³n sin ruido (odometrÃ­a) del robot, junto a 100 partÃ­culas 
% que indican posibles posiciones del robot (en base a otras tantas acciones de 
% control ruidosas).

cuadrado_particulas(10)
%% 
%