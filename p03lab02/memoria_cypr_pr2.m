%% Memoria de ejercicios puntuables de localizaciÃ³n
% 
% 
% Se entregarÃ¡ un Ãºnico archivo comprimido (PR2.zip), conteniendo una Ãºnica 
% memoria en PDF (memoria_cypr_pr2.pdf) con indicaciÃ³n de los ejercicios que se 
% han resuelto, comentarios sobre el mismo y capturas de pantalla que justifiquen 
% el funcionamiento (no aÃ±adir el cÃ³digo a la memoria). Finalmente, un archivo 
% Matlab en formato live_script (*.mlx) por cada ejercicio realizado.
%% 
% * Alumno: Ricardo Panero Lamothe
% * Asignatura: Control y ProgramaciÃ³n de Robots
% * Curso: 2022/23
% * Plazo de entrega: 12-dic-2022
%% Ejercicio puntuable - LSE
%% Ejercicio puntuable - FP
% ImplementaciÃ³n del filtro de partÃ­culas
% a) Medida sensorÃ­al
% Utilizando un mapa de landmarks como el empleado en los  ejercicios anteriores, 
% implementa ahora una funciÃ³n que tome como entrada la  pose del robot, seleccione 
% aleatoriamente un solo landmark de entre todos los  disponibles, y devuelva 
% la observaciÃ³n del sensor a dicho landmark. Dicha  observaciÃ³n estarÃ¡ compuesta 
% por las medidas de distancia y Ã¡ngulo entre el robot  y el landmark seleccionado, 
% afectadas por el ruido del sensor siguiendo su modelo  de ruido en base a la 
% matriz de covarianza

% Inicializamos el mapa
close all;
clear all;
Mapa={};
Mapa.nLandmarks = 7;
Mapa.Size = 20;      
Mapa.Landmarks = crear_landmarks(Mapa);

% Inicializamos el robt
Robot={};
Robot.xTrue=[5 -5 pi/2]' % posiciÃ³n inicial del robot
Robot.xOdom=[5 -5 pi/2]';
Robot.CovSensor = diag([0.5^2 (0.5*pi/180)^2]);

% Leemos la observaciÃ³n 
observacion=leer_sensor(Mapa, Robot)
% b) AcciÃ³n de control
% Programa el movimiento del robot como en prÃ¡cticas  anteriores, buscando realizar 
% un cuadrado de lado 10m, y estando las acciones de  control afectadas por cierto 
% ruido aleatorio en base a la matriz de covarianza de acciones
% 
% En este punto, tendremos la pose odomÃ©trica (xOdom), es decir, donde el robot  
% cree que estÃ¡, la pose real (xTrue), es decir, donde el robot estÃ¡ realmente 
% (esta  pose, aunque la simularemos en este ejercicio, es desconocida por el 
% robot y es la  que se quiere estimar con el sistema de localizaciÃ³n), y deberemos 
% generar un  nÃºmero de N poses candidatas (samples), dadas por las partÃ­culas 
% del filtro que  estamos implementando. Considerar N=100.

%Robot.plot = drawrobot(Robot.xTrue, 'b');
Robot.u_avance = [1 0 0]'; % accion de avance sin ruido
Robot.u_giro = [0 0 pi/2]'; % acciÃ³n de giro a la izquierda
Robot.CovU = diag([0.5^2 0.5^2 (0.5*pi/180)^2]); % covarianzas
Robot.Particles = 100;
Robot.xProb = zeros(3, Robot.Particles);

for i=1:44
    if mod(i,11)==0
        u=Robot.u_giro;
    else
        u=Robot.u_avance;
    end
    % posiciÃ³n odomÃ©trica
    Robot.xOdom=pose_comp(Robot.xOdom, u);
    plot(Robot.xOdom(1), Robot.xOdom(2), 'r.');

    % posiciÃ³n real afectada por el ruido
    noise=sqrt(Robot.CovU)*randn(3, 1);
    Robot.xTrue=pose_comp(Robot.xTrue, pose_comp(u, noise));
    plot(Robot.xTrue(1), Robot.xTrue(2), 'k.');
    
    % lectura de un sensor aleatorio (ver apartado c)
    observacion=leer_sensor(Mapa, Robot)

    % generaciÃ³n de partÃ­culas
    for j=1:Robot.Particles
        noise=sqrt(Robot.CovU)*randn(3, 1);
        Robot.xProb(:,j)=pose_comp( ...
            Robot.xProb(:,j), pose_comp(u, noise));
    end
    if (mod(i, 11)==0)
        part=plot(Robot.xProb(1,:), Robot.xProb(2,:), '.');
        set(part, 'MarkerSize', 5, 'Color', [rand rand rand]);
    end

    % pesos del FP (ver apartado d)
    w= 
end

% c) ActualizaciÃ³n de poses
% Programa que en cada iteraciÃ³n el robot realiza una acciÃ³n  de control (para 
% avanzar en el cuadrado) y recibe una mediciÃ³n del sensor a un  landmark aleatorio 
% del mapa (usando la funciÃ³n del apartado anterior). Con esta  informaciÃ³n, deberemos 
% actualizar las poses xOdom y xTrue, asÃ­ como las poses de  todas las samples 
% (considerando para cada una de ellas una muestra de ruido  diferente). Visualiza 
% en cada iteraciÃ³n estas poses.
% 
% 
% 
% observacion=leer_sensor(Mapa, Robot)
% d) Pesos del FP
% Para poder estimar la pose real del robot a partir de las N partÃ­culas  del 
% filtro, partimos de que la posiciÃ³n de los landmarks es conocida en el mapa. 
% El  objetivo ahora es poder discernir cuales de las N partÃ­culas actuales representan  
% adecuadamente la pose real del robot y cuÃ¡les no (recuerda que la pose xTrue 
% es  desconocida, y por tanto no se puede usar en los cÃ¡lculos). Para ello, asocia 
% a cada  partÃ­cula un peso W(i) que indique cÃ³mo de probable es la pose que representa  
% dicha partÃ­cula con respecto a las observaciones que toma el robot. Inicialmente  
% consideraremos que todas las partÃ­culas tienen el mismo peso, y por comodidad  
% impondremos que la suma de todos los pesos resulte 1 en todo momento  (normalizaciÃ³n).
% 
% El peso de cada partÃ­cula W(i) se actualiza en cada iteraciÃ³n atendiendo a 
% la  diferencia existente entre la medida del sensor (distancia y Ã¡ngulo afectados 
% por  ruido) que se ha obtenido en este paso (ver apartado a), y la distancia 
% y Ã¡ngulo que  hay desde la partÃ­cula considerada al landmark seleccionado. Es 
% decir: 
% 
% ğ‘Š(ğ‘–) = ğ‘“(z - zPre)
% 
% donde z es la medida sensorial que toma el robot desde el ground-truth con 
% el  sensor real (ğ‘Ÿ, ğœ™) y por tanto afectado por ruido, y zPred es la medida 
% hipotÃ©tica  que tomarÃ­a desde cada una de las partÃ­culas hasta el mismo landmark. 
% La funciÃ³n f puede ser cualquier funciÃ³n que asigne mayores valores a aquellas 
% partÃ­culas con la menor discrepancia, es decir, con z-Zpred mÃ¡s bajos. Una posible 
% funciÃ³n es: 
% 
% W(i)=exp(-0.5*(z-zPred)'*inv(Sigma_sensor)*(z-zPred))+0.001; 
% 
% Es decir, una funciÃ³n gaussiana utilizando la matriz de covarianza del modelo 
% del  sensor. Implementa esta funciÃ³n para que se vayan actualizando los pesos 
% de las  partÃ­culas en cada iteraciÃ³n.
% e) SelecciÃ³n de partÃ­culas
% f) EstimaciÃ³n de la pose del robot
%% 
% 
% Ejercicio puntuable
% a) Filtro sin correcciones
% b) Correcciones cada 5 pasos

clc;
%% PrÃ¡ctica 1. Modelo de movimiento
% En esta prÃ¡ctica vamos a implementar el modelo de movimiento basado en odometrÃ­a 
% mediante la tÃ©cnica de sampling. Comenzaremos implementando funciones bÃ¡sicas 
% que utilizaremos a lo largo de la prÃ¡ctica.
%% 1 ComposiciÃ³n de poses
% Implementa una funciÃ³n que realice la composiciÃ³n de dos poses, es decir que 
% dadas ğ‘ğ‘1 = [ğ‘¥ğ‘¥1 ğ‘¦ğ‘¦1 ğœƒğœƒ1]ğ‘‡ğ‘‡ y ğ‘ğ‘2 = [ğ‘¥ğ‘¥2 ğ‘¦ğ‘¦2 ğœƒğœƒ2]ğ‘‡ğ‘‡, devuelva 
% el resultado de la operaciÃ³n ğ‘ğ‘1 âŠ• ğ‘ğ‘2

pose_comp([-2.5 0 pi/2]', [0.2 0 -10*pi/180]')
%% 2 Modelo de odometrÃ­a
% DiseÃ±a un programa que iterativamente comande un robot para seguir una trayectoria 
% en forma de cuadrado de lado 10 metros. Para ello necesitarÃ¡s hacer uso de la 
% composiciÃ³n de poses para calcular en cada iteraciÃ³n ğ‘¥ğ‘¡ = ğ‘¥ğ‘¡âˆ’1 âŠ• ğ‘¢ğ‘¡, siendo 
% ğ‘¢ğ‘¡ = (Î”ğ‘¥ Î”y Î”ğœƒ)ğ‘‡. Considera que en cada paso el robot puede avanzar 1 metro 
% o girar 90â°. 

cuadrado(10);
%% 3 Comandando mediante velocidad lineal y angular
% Repite el ejercicio anterior (cuadrado de lado 10 metros), pero utilizando 
% en este caso una acciÃ³n de control ğ‘¢ğ‘¡ = (Vp W)ğ‘‡ formada por una velocidad 
% lineal y otra angular. 
% 
% Asume que dichos comandos de velocidad se aplican al robot cada 0.5s. Los 
% comandos se calculan de las siguientes ecuaciones:
% 
% x(Î”t) = âˆ«vP (t) cos(wt)dt
% 
% y(Î”t) = âˆ«vP (t) sin(wt)dt
% 
% Î¸ (Î”t) = âˆ« w(t) dt

cuadrado_velocidades(10);
%% 4 AÃ±adiendo ruido
% Modifica el ejercicio 2 para que la acciÃ³n de control se vea afectada por 
% ruido. Dibuja la trayectoria del robot con y sin ruido y comprueba cÃ³mo varÃ­a 
% para diferentes valores de sigma

cuadrado_ruido(10)
%% 5 Usando partÃ­culas
% Vamos a estimar la posiciÃ³n del robot en base a partÃ­culas, â€œsamplesâ€ de poses 
% probables en las que se puede encontrar el vehÃ­culo, atendiendo a la naturaleza 
% probabilÃ­stica del ruido que estamos considerando. Para ello repite el ejercicio 
% 4, mostrando la posiciÃ³n sin ruido (odometrÃ­a) del robot, junto a 100 partÃ­culas 
% que indican posibles posiciones del robot (en base a otras tantas acciones de 
% control ruidosas).

cuadrado_particulas(10)
%% 
%